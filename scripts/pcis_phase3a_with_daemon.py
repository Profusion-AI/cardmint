#!/usr/bin/env python3
"""Phase 3A with KeepWarm Daemon Integration - Optimized Performance Test.

This script demonstrates Phase 3A performance with the CardMint KeepWarm daemon,
eliminating the 3.5s warmup penalty and 36.5% cold-start variance.

Key improvements over standalone Phase 3A:
- No warmup protocol needed (daemon maintains warm state)
- Immediate inference capability
- Consistent performance from first card
- Real-time production-ready behavior

Configuration: 768 context + 40 max_tokens (Phase 3A optimal)
"""
from __future__ import annotations

import argparse
import base64
import datetime as dt
import json
import psutil
import sys
import time
from io import BytesIO
from pathlib import Path
from typing import Any, Dict, Iterable, List, Tuple
from urllib.parse import urlparse

from openai import OpenAI
from PIL import Image

# Import daemon integration
from daemon_integration import require_keepwarm_daemon

DEFAULT_SERVER_URL = "http://127.0.0.1:12345/v1"
DEFAULT_MODEL_ID = "mistralai/magistral-small-2509"

# Phase 3A optimal configuration
SYSTEM_PROMPT = (
    "You are a PokÃ©mon card identification assistant. Given an image, respond "
    "only with JSON containing name, hp, and set_number fields. Do not include "
    "confidence values or extra commentary.\n\n"
    "IMPORTANT: For set_number identification, look specifically in the bottom 15% "
    "of the image in either the left or right corner. The set number appears as "
    "a fraction format like '25/102' or just a number like '25'. Do NOT confuse "
    "this with level indicators (LV.XX) or other text elements on the card.\n\n"
    "CRITICAL: Output ONLY valid JSON. No reasoning, no explanations, no thinking process. "
    "Identify the Pokemon card directly and respond immediately with ONLY the JSON: "
    "{\"name\": \"...\", \"hp\": 123, \"set_number\": \"...\"}"
)

RESPONSE_SCHEMA: Dict[str, Any] = {
    "type": "json_schema",
    "json_schema": {
        "name": "pokemon_card_identity",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "hp": {"type": "integer"},
                "set_number": {"type": "string"},
            },
            "required": ["name", "hp", "set_number"],
            "additionalProperties": False,
        },
    },
}

FIRST_TEN_DIR = Path.home() / "Pictures" / "pokemoncards" / "first-ten"
GROUND_TRUTH_JSON = Path.home() / "Pictures" / "pokemoncards" / "pokemon_cards.json"


def encode_image_to_data_url(image_path: Path) -> Tuple[str, Dict[str, float]]:
    """Load image, ensure RGB, and return a data URL with base64 content plus timing."""
    timing = {}

    load_start = time.perf_counter()
    with Image.open(image_path) as img:
        timing['image_load_ms'] = (time.perf_counter() - load_start) * 1000

        convert_start = time.perf_counter()
        rgb_image = img.convert("RGB")
        timing['rgb_convert_ms'] = (time.perf_counter() - convert_start) * 1000

        encode_start = time.perf_counter()
        buffer = BytesIO()
        rgb_image.save(buffer, format="PNG")
        encoded = base64.b64encode(buffer.getvalue()).decode("ascii")
        timing['base64_encode_ms'] = (time.perf_counter() - encode_start) * 1000

        timing['total_encode_ms'] = sum(timing.values())

        return f"data:image/png;base64,{encoded}", timing


def load_ground_truth(path: Path) -> Dict[str, Dict[str, Any]]:
    """Load ground-truth metadata keyed by card ID (derived from filenames)."""
    with path.open("r", encoding="utf-8") as f:
        records: List[Dict[str, Any]] = json.load(f)
    return {record["id"]: record for record in records}


def build_messages(image_data_url: str) -> List[Dict[str, Any]]:
    return [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "Identify the PokÃ©mon card."},
                {"type": "image_url", "image_url": {"url": image_data_url}},
            ],
        },
    ]


def parse_prediction(raw_content: str) -> Dict[str, Any]:
    try:
        return json.loads(raw_content)
    except json.JSONDecodeError as exc:
        raise ValueError(f"Model output is not valid JSON: {raw_content}") from exc


def normalize_card_id(image_path: Path) -> str:
    return image_path.stem


def resolve_truth_set_number(truth: Dict[str, Any], card_id: str) -> str:
    """Return the best available set number string for comparisons and logs."""
    image_url = truth.get("image_url", "")
    if image_url:
        parsed = urlparse(image_url)
        stem = Path(parsed.path).stem
        if stem:
            number_part = stem.split("_")[0]
            if number_part:
                return number_part

    if "-" in card_id:
        return card_id.split("-", 1)[1]

    card_number = str(truth.get("card_number", "")).strip()
    if card_number and card_number.lower() != "nan":
        return card_number
    return card_id


def compare_fields(pred: Dict[str, Any], truth: Dict[str, Any], card_id: str) -> Dict[str, bool]:
    expected_name = truth.get("name", "").strip().lower()
    expected_hp = truth.get("hp")
    expected_card_number = resolve_truth_set_number(truth, card_id).strip().lower()

    provided_name = str(pred.get("name", "")).strip().lower()
    provided_hp = pred.get("hp")
    provided_set_number = str(pred.get("set_number", "")).strip().lower()

    set_number_matches = provided_set_number == expected_card_number or (
        expected_card_number and expected_card_number in provided_set_number
    )

    return {
        "name_correct": provided_name == expected_name,
        "hp_correct": provided_hp == expected_hp,
        "set_number_correct": set_number_matches,
    }


def identify_card(
    client: OpenAI, image_path: Path, *, max_tokens: int = 40  # Phase 3A optimal
) -> Tuple[Dict[str, Any], Dict[str, float]]:
    """Identify a card with daemon-warmed system - no warmup overhead."""
    timing = {}

    # Time image encoding
    encode_start = time.perf_counter()
    data_url, encode_timing = encode_image_to_data_url(image_path)
    timing.update(encode_timing)

    # Time API call preparation
    prep_start = time.perf_counter()
    messages = build_messages(data_url)
    timing['api_prep_ms'] = (time.perf_counter() - prep_start) * 1000

    # Time inference (no warmup needed - daemon maintains warm state)
    inference_start = time.perf_counter()
    response = client.chat.completions.create(
        model=DEFAULT_MODEL_ID,
        messages=messages,
        temperature=0,
        seed=0,
        max_tokens=max_tokens,
        response_format=RESPONSE_SCHEMA,
        # Phase 3A optimal context
        extra_body={"context_length": 768}
    )
    timing['inference_ms'] = (time.perf_counter() - inference_start) * 1000

    # Time parsing
    parse_start = time.perf_counter()
    raw_content = response.choices[0].message.content
    if raw_content is None:
        raise RuntimeError("Model returned empty content")
    prediction = parse_prediction(raw_content)
    timing['parse_ms'] = (time.perf_counter() - parse_start) * 1000

    # Calculate total time
    timing['total_card_ms'] = (
        timing['total_encode_ms'] +
        timing['api_prep_ms'] +
        timing['inference_ms'] +
        timing['parse_ms']
    )

    return prediction, timing


def evaluate_batch(image_paths: Iterable[Path]) -> Tuple[List[Dict[str, Any]], Dict[str, int], Dict[str, float]]:
    client = OpenAI(base_url=DEFAULT_SERVER_URL, api_key="lm-studio")
    truth = load_ground_truth(GROUND_TRUTH_JSON)

    # NO WARMUP NEEDED - daemon maintains warm state
    print("ğŸš€ Daemon-warmed system: Starting immediate inference...")

    results: List[Dict[str, Any]] = []
    tally = {"name_correct": 0, "hp_correct": 0, "set_number_correct": 0}
    timing_totals = {
        "total_batch_ms": 0,
        "total_inference_ms": 0,
        "total_encode_ms": 0,
        "total_parse_ms": 0,
        "card_count": 0
    }

    batch_start = time.perf_counter()

    for i, image_path in enumerate(image_paths, 1):
        card_id = normalize_card_id(image_path)
        ground_truth = truth.get(card_id)
        if not ground_truth:
            print(f"[WARN] No ground truth for {card_id}; skipping.", file=sys.stderr)
            continue

        print(f"ğŸ” Processing card {i}/{len(list(image_paths))}: {card_id}")

        card_start = time.perf_counter()
        prediction, timing = identify_card(client, image_path)
        card_total_ms = (time.perf_counter() - card_start) * 1000

        truth_set_number = resolve_truth_set_number(ground_truth, card_id)
        comparison = compare_fields(prediction, ground_truth, card_id)

        for key, value in comparison.items():
            if value:
                tally[key] += 1

        # Accumulate timing statistics
        timing_totals["total_inference_ms"] += timing["inference_ms"]
        timing_totals["total_encode_ms"] += timing["total_encode_ms"]
        timing_totals["total_parse_ms"] += timing["parse_ms"]
        timing_totals["card_count"] += 1

        # Result record
        result_record = {
            "image_file": str(image_path),
            "predicted_name": prediction.get("name"),
            "predicted_hp": prediction.get("hp"),
            "predicted_set_number": prediction.get("set_number"),
            "ground_truth_name": ground_truth.get("name"),
            "ground_truth_hp": ground_truth.get("hp"),
            "ground_truth_set_number": truth_set_number,
            "ground_truth_set_number_raw": ground_truth.get("card_number"),
            "inference_time_ms": round(timing["inference_ms"], 2),
            "encode_time_ms": round(timing["total_encode_ms"], 2),
            "parse_time_ms": round(timing["parse_ms"], 2),
            "total_card_time_ms": round(card_total_ms, 2),
        }
        result_record.update(comparison)
        results.append(result_record)

        # Real-time feedback
        print(f"   âœ… {card_id}: {timing['inference_ms']:.0f}ms inference")

    timing_totals["total_batch_ms"] = (time.perf_counter() - batch_start) * 1000

    # Calculate averages
    if timing_totals["card_count"] > 0:
        timing_totals["avg_inference_ms"] = timing_totals["total_inference_ms"] / timing_totals["card_count"]
        timing_totals["avg_encode_ms"] = timing_totals["total_encode_ms"] / timing_totals["card_count"]
        timing_totals["avg_parse_ms"] = timing_totals["total_parse_ms"] / timing_totals["card_count"]
        timing_totals["avg_card_ms"] = timing_totals["total_batch_ms"] / timing_totals["card_count"]
        timing_totals["cards_per_second"] = timing_totals["card_count"] / (timing_totals["total_batch_ms"] / 1000)

    return results, tally, timing_totals


def write_results(results: List[Dict[str, Any]], output_path: Path) -> None:
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(results, f, indent=2)


def determine_output_path(prefix: str = "id-results-phase3a-daemon") -> Path:
    timestamp = dt.datetime.now().strftime("%d%b%y")
    filename = f"{prefix}-{timestamp}.json"
    return Path(filename)


def collect_first_ten() -> List[Path]:
    if not FIRST_TEN_DIR.exists():
        raise FileNotFoundError(f"Missing directory: {FIRST_TEN_DIR}")
    return sorted(FIRST_TEN_DIR.glob("*.png"))


def main(args: argparse.Namespace) -> int:
    # DAEMON INTEGRATION: Require keepwarm daemon to be running
    daemon_health = require_keepwarm_daemon()

    image_paths = collect_first_ten()
    if not image_paths:
        print("No images found in first-ten directory.", file=sys.stderr)
        return 1

    print(f"ğŸš€ CardMint PHASE 3A with KeepWarm Daemon Integration")
    print(f"Target: {DEFAULT_SERVER_URL} | Model: {DEFAULT_MODEL_ID}")
    print(f"Configuration: 768 context + 40 max_tokens (daemon-warmed system)")
    print(f"Expected: No warmup delay, consistent performance from first card")
    print("=" * 80)

    # Execute batch with daemon-warmed system
    results, tally, timing_stats = evaluate_batch(image_paths)
    output_path = determine_output_path()
    write_results(results, output_path)

    # Performance metrics
    print(f"\nğŸ“Š DAEMON-WARMED PHASE 3A PERFORMANCE")
    print(f"Total batch time: {timing_stats['total_batch_ms']:.0f}ms ({timing_stats['total_batch_ms']/1000:.1f}s)")
    print(f"Cards processed: {timing_stats['card_count']}")
    print(f"Average per card: {timing_stats['avg_card_ms']:.1f}ms")
    print(f"Throughput: {timing_stats['cards_per_second']:.3f} cards/sec")
    print(f"Average inference: {timing_stats['avg_inference_ms']:.1f}ms")

    # Accuracy results
    print(f"\nğŸ¯ DAEMON-WARMED ACCURACY RESULTS")
    total_cards = len(results)
    name_acc = tally['name_correct'] / total_cards * 100
    hp_acc = tally['hp_correct'] / total_cards * 100
    set_acc = tally['set_number_correct'] / total_cards * 100
    avg_acc = (name_acc + hp_acc + set_acc) / 3

    print(f"Name accuracy: {tally['name_correct']}/{total_cards} ({name_acc:.1f}%)")
    print(f"HP accuracy: {tally['hp_correct']}/{total_cards} ({hp_acc:.1f}%)")
    print(f"Set number accuracy: {tally['set_number_correct']}/{total_cards} ({set_acc:.1f}%)")
    print(f"Average accuracy: {avg_acc:.1f}%")

    if avg_acc >= 95.0:
        print(f"âœ… SUCCESS: {avg_acc:.1f}% meets â‰¥95% accuracy target")
    else:
        print(f"âš ï¸  WARNING: {avg_acc:.1f}% below 95% accuracy target")

    # Comparison with standalone Phase 3A
    standalone_avg_inference = 11931  # From Phase 3A warmed system
    daemon_improvement = ((standalone_avg_inference - timing_stats['avg_inference_ms']) / standalone_avg_inference) * 100

    print(f"\nğŸ“ˆ DAEMON vs STANDALONE PHASE 3A COMPARISON")
    print(f"Standalone Phase 3A (with warmup): {standalone_avg_inference:.0f}ms average")
    print(f"Daemon-warmed Phase 3A: {timing_stats['avg_inference_ms']:.0f}ms average")

    if daemon_improvement > 0:
        print(f"âœ… DAEMON IMPROVEMENT: {daemon_improvement:.1f}% faster")
    else:
        print(f"â¡ï¸ PERFORMANCE EQUIVALENT: Consistent with warmed system")

    print(f"ğŸ¯ DAEMON BENEFITS:")
    print(f"  â€¢ No 3.5s warmup delay")
    print(f"  â€¢ Immediate inference capability")
    print(f"  â€¢ Consistent performance from first card")
    print(f"  â€¢ Production-ready real-time operation")

    print(f"\nğŸ’¾ Results saved to: {output_path}")
    return 0


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    exit_code = main(parser.parse_args())
    sys.exit(exit_code)